# 1강. 데이터 분석과 오픈소스의 이해

## 데이터 분석의 이해

- 정보는 데이터를 목적에 맞게 가공한 결과물
- 데이터 분석 - 데이터에 숨겨진 의미를 발견하고, 이를 바탕으로 의사결정에 활용할 수 있는 인사이트를 도출하는 일련의 과정
- 데이터 분석의 4단계: 설명적 분석, 진단적 분석, 예측적 분석, 처방적 분석
- 전통적 통계 분석 → 데이터베이스와 BI 활용 → 빅데이터와 ML의 발전

## 데이터의 특징과 데이터 분석 과정

- 데이터 수집 및 저장 → 데이터 전처리 → 데이터 분석 → 데이터 시각화
- 정형 데이터, 비정형 데이터, 반정형 데이터

## 오픈소스의 이해

- 리처드 스톨먼(RMS) - GNU 프로젝트 시작, 자유 소프트웨어 재단(FSF) 설립

# 2강. 데이터 분석을 위한 파이썬 프로그래밍 1

## 시퀸스 슬라이싱과 컴프리헨션

- 리스트 슬라이싱 - 대상 리스트의 부분 리스트를 생성 또는 수정
- 응용 - list1 = numbers[ : : 2 ], ist2 = numbers[ : : -1]
- 리스트 컴프리헨션 - numbers = [ i for i in range(5) ]
- 딕셔너리 컴프리헨션

## 문자열 형식 지정

- 오류가 없는 간결한 문법적 표현으로 보다 효율적이고 가독성 높은 코드를 작성하는 방법 필요
    - C 스타일(% 연산자) 포맷팅
    - str.format( ) 메서드를 이용한 포맷팅
    - f-문자열 포맷팅

## 컨텍스트 관리

- 리소스는 획득 및 사용 후 명시적으로 폐기
- 컨텍스트 관리(context management) - 자원을 사용 후 명시적으로 폐기해 주어야 하는 자원의 획득과 해제를 자동으로 처리, with 키워드를 사용해서 자동으로 처리

# 3강. 데이터 분석을 위한 파이썬 프로그래밍 2

## 파이썬 문법 요소

- 언패킹 - 시퀀스 자료형(리스트, 튜플, 문자열 등)에서 여러 개의 값을 개별 변수에 분리하여 할당하는 기능
    - 시퀀스 언패킹, 확장 언패킹
- 언더스코어 - 언더스코어( _ )는 반복 변수의 값이 필요하지 않을 때 이를 대체하는 역할
- 예외처리의 이해 - try-except 문의 사용, finally 블록의 사용

## 함수형 프로그래밍

- 데이터 변경을 최소화하고, 순수 함수(pure function)를 활용하여 부작용(side effect)을 줄이는 것을 목표
    - 순수함수: 같은 입력에 대해 항상 같은 출력을 반환하는 함수
    - 부작용: 함수가 단순히 값을 계산하는 것 외에 외부에 영향을 미치는 모든 행위
- 람다 함수 - 이름이 없는 익명 함수(anonymous function), 한 줄의 표현식으로 작성할 수 있는 간결한 함수, 단 하나의 표현식만 허용, 표현식의 결과는 자동으로 함수의 반환값이 되므로 return 키워드 사용하지 않음

# 4강. 데이터의 수집

## 데이터 수집의 이해

-

## 데이터의 유형

- 정형 데이터 - 미리 정의된 스키마에 따라 행과 열로 구성된 테이블 형태로 저장되는 데이터
- 비정형 데이터 - 정형 데이터에 비해 분석하기 어렵지만, 다양한 정보와 맥락을 포함
- 반정형 데이터 - 어느 정도의 구조화된 요소를 포함하지만, 정형 데이터와 같이 엄격한 스키마나 고정된 형식을 따르지 않음

## 데이터 수집 방법

-

```python
import pandas as pd

## data.csv 파일 읽기
df = pd.read_csv('data.csv', encoding='utf-8', sep=',', header=0, index_col=None, skiprows=None, nrows=None)

print(df)
```

```python
import json
import pandas as pd

## data.json 파일 출력
with open('data.json', mode='r', encoding='utf-8') as f:
  data = json.load(f)
print(data)

## data.json 파일 DataFrame 읽기
df = pd.read_json('data.json', orient='records', encoding='utf-8')

print(df)
```

```python
import re

## 파일(callcenter20250301.log) 오픈 및 읽기
with open('callcenter20250301.log', 'r', encoding='utf-8') as f:
    content = f.read()
## 주민등록번호 패턴 생성
pattern = re.compile(r'(\d{6}-\d{7})')

## 주민등록번호 마스킹
masked_content = pattern.sub(r'\1-*******', content)

## 마스킹된 파일(callcenter20250301_masked.log) 오픈 및 쓰기
with open('callcenter20250301_masked.log', mode='w') as f:
  f.write(masked_content)

print("주민등록번호 마스킹 완료. 'callcenter20250301_masked.log.txt' 파일로 저장되었습니다.")
```

```python
import requests
import json

url = "https://api.open-meteo.com/v1/forecast?=&=&current=temperature_2m"
params = {
    "latitude": "37.58638333",
    "longitude": "127.0203333",
    "current": "temperature_2m"
}

try:
    ## URL 및 파라미터 전송
    response = requests.get(url, params=params)
    response.raise_for_status()

    ## JSON 데이터 읽기
    data = response.json()

    print("API 응답:", data)
    print("서울시 종로구의 현재 온도는 : {0}{1} 입니다.".format(data['current']['temperature_2m'], data['current_units']['temperature_2m']))

except requests.exceptions.RequestException as e:
    print(f"API 호출 실패: {e}")
except json.JSONDecodeError as e:
    print(f"JSON 파싱 실패: {e}")
```

```python
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from lxml import html
import time

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')               # 브라우저 창 없이 실행
chrome_options.add_argument('--no-sandbox')             # 보안모드 비활성화 (Colab 필수)
chrome_options.add_argument('--disable-dev-shm-usage')  # 메모리 부족 방지 (Colab 필수)
chrome_options.add_argument('--window-size=1920x1080')  # 창 크기 설정(가상)
chrome_options.add_argument('--disable-gpu')            # GPU 가속 비활성화 (일부 환경 안정성)
chrome_options.binary_location = "/usr/bin/google-chrome-stable"  # Colab용 크롬 경로 지정

## 드라이버 실행
driver = webdriver.Chrome(options=chrome_options)

## 사이트 접속
url = 'https://professor.knou.ac.kr/jaehwachung/index.do'
driver.get(url)

## 사이트 접속 대기
time.sleep(2)

## 페이지 제목 출력
page_source = driver.page_source
tree = html.fromstring(page_source)

title_text = tree.xpath('//title/text()')
print(title_text)

## 드라이버 종료
driver.quit()
```

(+) 공공데이터 신청

# 5강. 데이터 저장

## 데이터 저장의 이해

- CSV, JSON, 데이터베이스

## Pandas DataFrame의 이해

- 2차원 테이블 형태의 자료구조

# 6강. 데이터 전처리 1

## 데이터 전처리의 이해

- GIGO(Garbage In, Garbage Out)
- 데이터 분석에 앞서 원시 데이터(raw data)를 정제하고 변환하여 분석에 적합한 형태로 만드는 일련의 작업
- 측정 → 정제 → 통합 → 축소 → 변환

## Pandas를 이용한 데이터 측정

-